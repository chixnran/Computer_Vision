经典的机器学习模型，用于解决分类和回归问题。

线性模型（Linear Models）：一种基本的统计模型，用于建立输入特征与输出之间的线性关系。基本形式是：y = w₁x₁ + ... + wₙxₙ + b，y表示输出变量，x₁, ..., xₙ表示输入特征，w₁, ..., wₙ表示特征的权重，b表示偏差或截距。模型通过学习特征的权重和偏差，以最小化预测值与真实值之间的差距。线性模型简单、可解释性强、计算效率高，适用于特征与输出之间存在线性关系的问题。
逻辑回归模型（Logistic Regression）：一种用于二分类问题的线性模型，通过逻辑函数（sigmoid函数）将线性模型的输出转化为概率值，从而进行分类。逻辑回归模型的基本形式是：p = 1 / (1 + exp(-(w₁x₁ + ... + wₙxₙ + b)))其中，p表示样本属于某个类别的概率。模型通过学习特征的权重和偏差，以最大化似然函数或最小化对数损失函数来拟合训练数据，并进行分类预测。逻辑回归模型模型简单、可解释性强、计算效率高，广泛应用于二分类问题。逻辑回归模型还可以通过正则化技术来防止过拟合。
区别：
输出类型：线性模型常用于回归问题，输出是连续值。逻辑回归模型用于二分类问题，输出是概率值或类别标签。
输出转换：线性模型直接使用线性函数进行预测。逻辑回归模型通过逻辑函数（sigmoid函数）将线性模型的输出转化为概率值，从而进行分类。
损失函数：线性模型通常使用均方误差MSE或平均绝对误差等回归损失函数。逻辑回归模型使用对数损失函数或交叉熵损失函数来最小化分类误差。
联系：
线性模型是逻辑回归模型的一种特例。当逻辑回归模型中只有一个二分类输出变量，并且特征与输出之间存在线性关系时，逻辑回归模型退化为线性模型。
逻辑回归模型可以使用线性模型的方法进行参数估计。逻辑回归模型的参数估计可以通过最大似然估计或梯度下降等方法来获得，类似于线性模型的参数估计。
